# 简介

一个用于实时流量分析的工具，包括嵌入式客户端，以及对应的服务器部分。嵌入式客户端嗅探网络流量，然后传输数据到对应的服务器处进行分析。另外，涉及分布式治理和无侵入式数据同步的概念，使用 ZK 同步客户端和服务器中的配置信息，使用 Canal 同步 MySQL 和 ZK 中的配置信息，也就是仅需操作数据库，便能更新客户端中的配置信息。总之，配置信息保存在服务器处，而不是客户端。

<div align=center>
  <p>
  <img src="./img/arch.svg">
  <figcaption>图：架构</figcaption>
  <p>
</div>

# 实现细节

## 客户端

使用 C 语言实现，分为配置和嗅探两个模块：（1）配置进程读取并监听 ZK 中的数据，作为嗅探进程的配置，当发现 ZK 中的数据更新时，重启嗅探进程，并且重复执行上述步骤；（2）嗅探进程使用 libpcap 嗅探网络流量，转储临时文件，每当采集一定的网络流量，便会使用 libcurl 将网络流量上传到分析服务器，期间使用 libuv 提供的任务队列功能异步传输数据，保证嗅探工作得以持续执行。

## 服务器

**Java 部分：** 使用 Java 语言实现，分为同步和分析两个模块：（1）同步服务器使用 Canal 监听 MySQL 中的数据，当发现 MySQL 中的数据发生增、删、改等变化时，使用 Kafka 传输对应的消息到同步服务器，从而同步 MySQL 和 ZK 中的数据；（2）分析服务器使用 Pcap4J 切割网络流量，由于网络流量无法全部转储 MySQL 中，因此使用 Redis 和 RabbitMQ 重组会话，在使用 OpenFeign 获得后端的 Python 部分的分析结果后，使用 MyBatis-Plus 存储网络流量的检测结果。其中，由于检测结果不像配置信息一样需要使用 Canal 进行同步，因此使用 ShardingSphere-JDBC 进行分库操作。

**Python 部分：** 使用 Python 语言实现，在使用 Flask 框架作为搭建服务器的基础上，使用 PyTorch 分析从 Redis 处获取的网络流量。

# 详细说明

## 客户端

监听器部分：

1）监听器连接 ZK，派生子线程；

2）监听器的主线程获取 ZK 中的配置信息，并且解析，包括嗅探的网络设备，BPF 表达式，以及服务器的地址。派生子进程（嗅探器），等待子进程运行结束。当子进程运行结束时，重复根据配置信息派生子进程；

3）监听器的子线程监听 ZK 中配置信息的更新。当数据更新时，获取、解析配置信息，然后通过信号的方式结束子进程。

注意：（1）主线程只会获取一次 ZK 中的配置信息，相反，子线程则是多次获取；（2）获取配置信息之后，主线程只会重复派生进程、等待后者运行结束的循环，更新的配置信息通过子线程获取；类似，子线程重复监听更新，获取、解析数据，以及停止子进程的操作；（3）由于 Linux 的特性，子进程的虚拟内存和信号集合只会复制当前线程的，出于主线程并未监听 ZK 中配置信息的缘故，子进程不会像主进程的子线程一样触发对应的监听操作。

嗅探器部分：

1）派生线程池，其中线程池屏蔽信号，只能主线程触发信号；

2）嗅探器嗅探网络流量，每当采集足够的数据便向线程池派发任务，任务的内容是向指定服务器上传嗅探的网络流量，其中网络流量暂存在本地的临时文件中；

3）当嗅探器触发信号时，依次执行停止嗅探、等待线程池中残留的任务全部运行完成、进程结束的操作。

注意：（1）嗅探的主线程嗅探网络流量，具体执行上传的操作由线程池来执行；（2）临时文件具备在关闭文件描述符和进程结束时自动删除的特性，因此适合作为缓冲。

## 服务器

配置服务器：

1）当 MySQL 中的配置信息发生变更时，Canal 向 Kafka 中发送对应的消息；

2）Config Listener 收到消息，按照消息增、删、改的类型，在 ZK 中做出对应的操作。

注意：只有在增、删、改时，Canal 才会发送对应的消息，查询不会触发消息传递的动作。

分析服务器：

1）SplitCap Controller 接收网络流量，按照如下代码片段分割网络流量，

```lua
if redis.call('SISMEMBER', 'done-session-entry', ARGV[1]) == 0 then
    local count = redis.call('ZCARD', 'session::' .. ARGV[1])
    if count < tonumber(KEYS[1]) then
        redis.call('ZADD', 'session::' .. ARGV[1], ARGV[2], ARGV[3])
        return count + 1
    end
end
```

其中，`ARGV[1]` 为会话的唯一编码，通过五元组（协议，源和目的的 IP 地址和端口号）生成，具有唯一性，`ARGV[2]` 为数据包的到达时刻，`ARGV[3]` 为数据包的负载内容，另外，`KEYS[1]` 为最大数据包数量 。因此，切割的会话会通过 RabbitMQ 送达 Session Listener，进行网络流量的检测和识别；

2）Session Listener 收到消息，首先通过 Feign 使用部署在 Flask 的 PyTorch 模型（Forecat App）进行预测，然后写入预测结果到 MySQL 中。

注意：项目设计的算法能够保证一定对网络流量进行分析，并且尽量具备实时的特性。

# 安装

[INSTALL.md](./INSTALL.md)
